<div align="center">
  <h1>Hi there, I'm Linfeng Tang (å”éœ–å³°) ğŸ‘‹</h1>
  
  <h3>PhD Student @ <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a></h3>
  
  <p>
    <b>Research Interests:</b> Multi-modal Image Fusion, Image Enhancement, Visual-Semantic Understanding
  </p>

  <a href="https://linfeng-tang.github.io/">
    <img src="https://img.shields.io/badge/ğŸ _Personal_Homepage-Visit_Now-2ea44f?style=for-the-badge&logo=github" alt="Website">
  </a>

  <p>
    <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
      <img src="https://img.shields.io/badge/Google_Scholar-PyRqpAsAAAAJ-4285F4?style=flat&logo=google-scholar&logoColor=white" alt="Google Scholar">
    </a>
    <a href="mailto:linfeng0419@gmail.com">
      <img src="https://img.shields.io/badge/Email-linfeng0419@gmail.com-D14836?style=flat&logo=gmail&logoColor=white" alt="Email">
    </a>
    <a href="https://www.researchgate.net/profile/Tang-Linfeng-2">
      <img src="https://img.shields.io/badge/ResearchGate-Linfeng_Tang-00CCBB?style=flat&logo=ResearchGate&logoColor=white" alt="ResearchGate">
    </a>
  </p>
</div>

---

<table>
  <tr>
    <td width="60%" valign="top">
      <h3>ğŸ”­ About Me</h3>
      <p>
        I am a PhD student at the <b>School of Electronic Information, Wuhan University</b>. My research primarily focuses on Computer Vision and Deep Learning.
      </p>
      <p>
        <b>Main Research Topics:</b>
      </p>
      <ul>
        <li><b>Information Fusion</b> (Multi-modal Image Fusion, Video Fusion)</li>
        <li><b>Image Enhancement</b> (Low-light Enhancement)</li>
        <li><b>Visual-Semantic Understanding</b></li>
      </ul>
    </td>
    <td width="40%" valign="center">
      <div align="center">
        <img src="https://github-readme-stats.vercel.app/api?username=Linfeng-Tang&show_icons=true&theme=radical&hide_border=true&bg_color=00000000" alt="Linfeng's github stats" />
      </div>
    </td>
  </tr>
</table>

---

### ğŸ”¥ Latest News

- **[2025-12-26]** ğŸ† æˆ‘ä»¬çš„ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://www.cjig.cn/thesisDetails#10.11834/jig.220422&lang=zh)ã€‹è£è· **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2020-2024 ä¼˜ç§€è®ºæ–‡**ï¼
- **[2025-9-18]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ **"ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts"** è¢« **NeurIPS 2025** æ­£å¼æ¥æ”¶! [[è®ºæ–‡ä¸‹è½½](https://arxiv.org/pdf/2503.23356?)] [[Code](https://github.com/Linfeng-Tang/ControlFusion)]
- **[2025-9-10]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ **"Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion"** è¢« **IEEE TPAMI** æ­£å¼æ¥æ”¶! [[è®ºæ–‡ä¸‹è½½](https://ieeexplore.ieee.org/document/11162636)] [[Code](https://github.com/Linfeng-Tang/Mask-DiFuser)]
- **[2025-3-15]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ã€Š[C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning](https://github.com/Linfeng-Tang/C2RF)ã€‹è¢« **IJCV** æ­£å¼æ¥æ”¶ï¼[[è®ºæ–‡ä¸‹è½½](https://link.springer.com/article/10.1007/s11263-025-02427-1)] [[Code](https://github.com/Linfeng-Tang/C2RF)]
- **[2025-02-11]** ğŸ“‚ æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªç”¨äºçº¢å¤–å’Œå¯è§å…‰è§†é¢‘èåˆçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼š[M3SVDï¼šMulti-Modal Multi-Scene Video Dataset](https://github.com/Linfeng-Tang/M3SVD).

<details>
<summary><b>ç‚¹å‡»æŸ¥çœ‹æ›´å¤šå¾€æœŸæ–°é—» (2024åŠä»¥å‰)</b></summary>

- **[2024-12-26]** ğŸ† ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‹è£è· **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2024 ä¼˜ç§€è®ºæ–‡**ï¼[[News](https://mp.weixin.qq.com/s?__biz=MzU1NzM4MjgzOA==&mid=2247536019&idx=1&sn=086193c8064ae58bc1f05de26faaee61)] [[Code](https://github.com/Linfeng-Tang/Image-Fusion)]
- **[2024-11-28]** ğŸ† æˆ‘ä»¬çš„è®ºæ–‡(SeAFusion)ã€Š[Image fusion in the loop of high-level vision tasks](https://www.sciencedirect.com/science/article/pii/S1566253521002542)ã€‹è£è· **Information Fusion Best Paper Award 2024** (æœ€ä½³è®ºæ–‡å¥–)ï¼[[Code](https://github.com/Linfeng-Tang/SeAFusion)]
- **[2024-09]** ğŸŒŸ ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‹å…¥é€‰ **ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡** (å…¨å›½å…±14ç¯‡)ï¼
- **[2024-07-16]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ã€Š[DRMF: Degradation-Robust Multi-Modal Image Fusion](https://openreview.net/forum?id=BwXrlBweab)ã€‹è¢« **ACM MM 2024** æ­£å¼æ¥æ”¶ï¼[[Code](https://github.com/Linfeng-Tang/DRMF)]
- **[2023-11]** ğŸ† æˆ‘ä»¬çš„è®ºæ–‡ã€Š[SwinFusion](https://ieeexplore.ieee.org/document/9812535)ã€‹è£è· **Hsue-shen Tsien Paper Award 2023 (é’±å­¦æ£®è®ºæ–‡å¥–)**ï¼[[Code](https://github.com/Linfeng-Tang/SwinFusion)]

</details>

---

### ğŸ“ Selected Publications

> For a full list, please visit my [Personal Homepage](https://linfeng-tang.github.io/).

#### 2025 & In Press
* **Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion** <br>
    *Linfeng Tang, Chunyu Li, Jiayi Ma* <br>
    **IEEE TPAMI**, vol. 48, no. 1, pp. 591-608, Jan. 2026. <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE_Xplore-blue)](https://doi.org/10.1109/TPAMI.2025.3609323) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/Mask-DiFuser)

* **ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts** <br>
    *Linfeng Tang, Yeda Wang, Zhanchuan Cai, Junjun Jiang, Jiayi Ma* <br>
    **NeurIPS 2025** (Oral, Acceptance rate: 0.36%). <br>
    [![Paper](https://img.shields.io/badge/Paper-OpenReview-b31b1b)](https://openreview.net/forum?id=aLhA7AYLLR) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/ControlFusion)

* **C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning** <br>
    *Linfeng Tang, Qinglong Yan, Xinyu Xiang, Leyuan Fang, Jiayi Ma* <br>
    **IJCV 2025**. <br>
    [![Paper](https://img.shields.io/badge/Paper-Springer-blue)](https://link.springer.com/article/10.1007/s11263-025-02427-1) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/C2RF)

#### Highlights (Awarded ğŸ† / ESI Hot & Highly Cited ğŸ”¥)

* ğŸ† **Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network** <br>
    *Linfeng Tang, Jiteng Yuan, Jiayi Ma* <br>
    **Information Fusion 2022**. (**Best Paper Award 2024**, ESI Hot & Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S1566253521002542) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SeAFusion)

* ğŸ† **SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer** <br>
    *Jiayi Ma, Linfeng Tang, et al.* <br>
    **IEEE/CAA JAS 2022**. (**Hsue-shen Tsien Paper Award 2023**, ESI Hot & Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9812535) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SwinFusion)

* ğŸ† **åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°** <br>
    *å”éœ–å³°, å¼ æµ©, å¾æ¶µ, é©¬ä½³ä¹‰* <br>
    **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2023**. (**ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ä¼˜ç§€è®ºæ–‡**, **ä¼˜ç§€æˆæœæŠ¥å‘Š**) <br>
    [![Paper](https://img.shields.io/badge/Paper-CJIG-red)](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/Image-Fusion)

* ğŸ”¥ **SuperFusion: A Versatile Image Registration and Fusion Network with Semantic Awareness** <br>
    *Linfeng Tang, Yuxin Deng, Yong Ma, Jun Huang, Jiayi Ma* <br>
    **IEEE/CAA JAS 2022**. (ESI Hot & Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9970457) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SuperFusion)

* ğŸ”¥ **Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity** <br>
    *Linfeng Tang, Hao Zhang, Han Xu, Jiayi Ma* <br>
    **Information Fusion 2023**. (ESI Hot & Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S1566253523001860) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/PSFusion)

* ğŸ”¥ **DIVFusion: Darkness-free infrared and visible image fusion** <br>
    *Linfeng Tang, Xinyu Xiang, Hao Zhang, Meiqi Gong, Jiayi Ma* <br>
    **Information Fusion 2023**. (ESI Hot & Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S156625352200210X?via%3Dihub) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/DIVFusion)

* ğŸ”¥ **PIAFusion: A progressive infrared and visible image fusion network based on illumination aware** <br>
    *Linfeng Tang, Jiteng Yuan, Hao Zhang, Xingyu Jiang, Jiayi Ma* <br>
    **Information Fusion 2022**. (ESI Hot & Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/PIAFusion)

* ğŸ”¥ **STDFusionNet: An Infrared and Visible Image Fusion Network Based on Salient Target Detection** <br>
    *Jiayi Ma, Linfeng Tang, Meilong Xu, Hao Zhang, Guobao Xiao* <br>
    **IEEE TIM 2021**. (ESI Highly Cited) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9416507) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/STDFusionNet)

<br>

<details>
<summary><b>ğŸ“œ Click to View Full List of Publications (1-15)</b></summary>

#### âš¡Publications:
1. **Linfeng Tang**, Chunyu Li, and Jiayi Ma. "Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion", IEEE Transactions on Pattern Analysis and Machine Intelligence (**IEEE TPAMI**), 48(1):591-608, 2026.ã€[Paper](https://doi.org/10.1109/TPAMI.2025.3609323)ã€‘ã€[Code](https://github.com/Linfeng-Tang/Mask-DiFuser)ã€‘
2. **Linfeng Tang**, Yeda Wang, Zhanchuan Cai, Junjun Jiang, and Jiayi Ma. "ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts", in Advances in Neural Information Processing Systems (NeurIPS), Dec. 2025 (Oral, Acceptance rate: 0.36%).ã€[Paper](https://openreview.net/forum?id=aLhA7AYLLR)ã€‘ã€[Code](https://github.com/Linfeng-Tang/ControlFusion)ã€‘
3. **Linfeng Tang**, Qinglong Yan, Xinyu Xiang, Leyuan Fang, and Jiayi Ma. "C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning", International Journal of Computer Vision (**IJCV**), 2025. ã€[Paper](https://github.com/Linfeng-Tang/C2RF)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/C2RF)ã€‘ 
4. **Linfeng Tang**, Jiteng Yuan, and Jiayi Ma. "Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network", Information Fusion, 82, pp. 28-42, 2022. (**Information Fusion Best Paper Award 2024 (æœ€ä½³è®ºæ–‡å¥–)**, å…¥é€‰ESIçƒ­ç‚¹&é«˜è¢«å¼•è®ºæ–‡)ã€[Paper](https://www.sciencedirect.com/science/article/pii/S1566253521002542)ã€‘ã€[Code](https://github.com/Linfeng-Tang/SeAFusion)ã€‘
5. Jiayi Ma, **Linfeng Tang**, Fan Fan, Jun Huang, Xiaoguang Mei, and Yong Ma. "SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer", IEEE/CAA Journal of Automatica Sinica, 9(7), pp. 1200-1217, 2022. (Hsue-shen Tsien Paper Award 2023 (é’±å­¦æ£®è®ºæ–‡å¥–ï¼ŒIEEE/CAA JASæœ€ä½³è®ºæ–‡å¥–, å…¥é€‰ESIçƒ­ç‚¹&é«˜è¢«å¼•è®ºæ–‡))ã€[Paper](https://ieeexplore.ieee.org/document/9812535)ã€‘ã€[Code](https://github.com/Linfeng-Tang/SwinFusion)ã€‘
6. **Linfeng Tang**, Yuxin Deng, Yong Ma, Jun Huang, and Jiayi Ma. "SuperFusion: A Versatile Image Registration and Fusion Network with Semantic Awareness", 9(12), pp. 2121-2137, 2022. (å…¥é€‰ESIçƒ­ç‚¹&é«˜è¢«å¼•è®ºæ–‡).ã€[Paper](https://ieeexplore.ieee.org/document/9970457)ã€‘ã€[Code](https://github.com/Linfeng-Tang/SuperFusion)ã€‘
7. **Linfeng Tang**, Hao Zhang, Han Xu, and Jiayi Ma. "Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity", Information Fusion, 99, pp. 101870, 2023. (å…¥é€‰ESIçƒ­ç‚¹&é«˜è¢«å¼•è®ºæ–‡)ã€[Paper](https://www.sciencedirect.com/science/article/pii/S1566253523001860)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/PSFusion)ã€‘ 
8. **Linfeng Tang**, Yuxin Deng, Xunpeng Yi, Qinglong Yan, Yixuan Yuan, and Jiayi Ma. "DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior", in Proceedings of the ACM International Conference on Multimedia (ACM MM), Nov. 2024.ã€[Paper](https://dl.acm.org/doi/10.1145/3664647.3681064)ã€‘ã€[Code](https://github.com/Linfeng-Tang/DRMF)ã€‘
9. **Linfeng Tang**, Xinyu Xiang, Hao Zhang, Meiqi Gong, and Jiayi Ma. "DIVFusion: Darkness-free infrared and visible image fusion", Information Fusion, 91, pp. 477-493, 2023. (å…¥é€‰ESIçƒ­ç‚¹&é«˜è¢«å¼•è®ºæ–‡)ã€[Paper](https://www.sciencedirect.com/science/article/pii/S156625352200210X?via%3Dihub)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/DIVFusion)ã€‘
10. **Linfeng Tang**, Jiteng Yuan, Hao Zhang, Xingyu Jiang, and Jiayi Ma. "PIAFusion: A progressive infrared and visible image fusion network based on illumination aware", Information Fusion, 83-84, pp. 79-92, 2022. (å…¥é€‰ESIçƒ­ç‚¹&é«˜è¢«å¼•è®ºæ–‡)ã€[Paper](https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X)ã€‘ã€[Code](https://github.com/Linfeng-Tang/PIAFusion)ã€‘
11. Â **Linfeng Tang**, Jiayi Ma, Hao Zhang, and Xiaojie Guo. "DRLIE: Flexible Low-light Image Enhancement via Disentangled Representations", IEEE Transactions on Neural Networks and Learning Systems, 35(2), pp. 2694-2707, 2024.ã€[Paper](https://ieeexplore.ieee.org/document/9833451)ã€‘ã€[Code](https://github.com/Linfeng-Tang/DRLIE)ã€‘
12. Jiayi Ma, **Linfeng Tang**, Meilong Xu, Hao Zhang, and Guobao Xiao. "STDFusionNet: An Infrared and Visible Image Fusion Network Based on Salient Target Detection", IEEE Transactions on Instrumentation and Measurement, 70, pp. Â 5009513, 2021.(å…¥é€‰ESIé«˜è¢«å¼•è®ºæ–‡)ã€[Paper](https://ieeexplore.ieee.org/document/9416507)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/STDFusionNet)ã€‘
13. Meilong Xu, **Linfeng Tang**, Hao Zhang, and Jiayi Ma. "Infrared and visible image fusion via parallel scene and texture learning", Pattern Recognition, 132, pp. 108929, 2022.ã€[Paper](https://www.sciencedirect.com/science/article/pii/S0031320322004101)ã€‘ã€[Code](https://github.com/Melon-Xu/PSTLFusion)ã€‘
14. **Linfeng Tang**, Ziang Chen, Jun Huang, and Jiayi Ma. "CAMF: An Interpretable Infrared and Visible Image Fusion Network Based on Class Activation Mapping", IEEE Transactions on Multimedia, 26, pp. 4776-4791, 2024.ã€[Paper](https://ieeexplore.ieee.org/document/10288391)ã€‘ã€[Code](https://github.com/Linfeng-Tang/CAMF)ã€‘
15. **å”éœ–å³°**, å¼ æµ©, å¾æ¶µ, é©¬ä½³ä¹‰. åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°. ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥, 28(1), pp. 3-36, 2023. (**ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ä¼˜ç§€è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ä¼˜ç§€æˆæœæŠ¥å‘Š**)ã€[Paper](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‘ã€[Code](https://github.com/Linfeng-Tang/Image-Fusion)ã€‘

</details>

<br>

<details>
<summary><b>ğŸ“š BibTeX (Click to copy)</b></summary>

```bibtex
@ARTICLE{11162636,
  author={Tang, Linfeng and Li, Chunyu and Ma, Jiayi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion}, 
  year={2026},
  volume={48},
  number={1},
  pages={591-608},
  doi={10.1109/TPAMI.2025.3609323}
}

@inproceedings{tang2025controlfusion,
  title={ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts},
  author={Tang, Linfeng and Wang, Yeda and Cai, Zhanchuan and Jiang, Junjun and Ma, Jiayi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2025},
  url={[https://openreview.net/forum?id=aLhA7AYLLR](https://openreview.net/forum?id=aLhA7AYLLR)}
}

@article{tang2025c2rf,
  title={C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning},
  author={Tang, Linfeng and Yan, Qinglong and Xiang, Xinyu and Fang, Leyuan and Ma, Jiayi},
  journal={International Journal of Computer Vision},
  year={2025},
  publisher={Springer}
}

@article{tang2022image,
  title={Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network},
  author={Tang, Linfeng and Yuan, Jiteng and Ma, Jiayi},
  journal={Information Fusion},
  volume={82},
  pages={28--42},
  year={2022},
  publisher={Elsevier}
}

@article{ma2022swinfusion,
  title={SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer},
  author={Ma, Jiayi and Tang, Linfeng and Fan, Fan and Huang, Jun and Mei, Xiaoguang and Ma, Yong},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={9},
  number={7},
  pages={1200--1217},
  year={2022},
  publisher={IEEE}
}

@article{tang2023rethinking,
  title={Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity},
  author={Tang, Linfeng and Zhang, Hao and Xu, Han and Ma, Jiayi},
  journal={Information Fusion},
  volume={99},
  pages={101870},
  year={2023},
  publisher={Elsevier}
}

@article{tang2023deep,
  title={åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°},
  author={å”éœ–å³° and å¼ æµ© and å¾æ¶µ and é©¬ä½³ä¹‰},
  journal={ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥},
  volume={28},
  number={1},
  pages={3--36},
  year={2023}
}
