<div align="center">
  <h1>Hi there, I'm Linfeng Tang (å”éœ–å³°) ğŸ‘‹</h1>
  
  <h3>PhD Student @ <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a></h3>
  
  <p>
    <b>Research Interests:</b> Multi-modal Image Fusion, Image Enhancement, Visual-Semantic Understanding
  </p>

  <a href="https://linfeng-tang.github.io/">
    <img src="https://img.shields.io/badge/ğŸ _Personal_Homepage-Visit_Now-2ea44f?style=for-the-badge&logo=github" alt="Website">
  </a>

  <p>
    <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
      <img src="https://img.shields.io/badge/Google_Scholar-PyRqpAsAAAAJ-4285F4?style=flat&logo=google-scholar&logoColor=white" alt="Google Scholar">
    </a>
    <a href="mailto:linfeng0419@gmail.com">
      <img src="https://img.shields.io/badge/Email-linfeng0419@gmail.com-D14836?style=flat&logo=gmail&logoColor=white" alt="Email">
    </a>
    <a href="https://www.researchgate.net/profile/Tang-Linfeng-2">
      <img src="https://img.shields.io/badge/ResearchGate-Linfeng_Tang-00CCBB?style=flat&logo=ResearchGate&logoColor=white" alt="ResearchGate">
    </a>
  </p>
</div>

---

<table>
  <tr>
    <td width="60%" valign="top">
      <h3>ğŸ”­ About Me</h3>
      <p>
        I am a PhD student at the <b>School of Electronic Information, Wuhan University</b>. My research primarily focuses on Computer Vision and Deep Learning.
      </p>
      <p>
        <b>Main Research Topics:</b>
      </p>
      <ul>
        <li><b>Information Fusion</b> (Multi-modal Image Fusion, Video Fusion)</li>
        <li><b>Image Enhancement</b> (Low-light Enhancement)</li>
        <li><b>Visual-Semantic Understanding</b></li>
      </ul>
    </td>
    <td width="40%" valign="center">
      <div align="center">
        <img src="https://github-readme-stats.vercel.app/api?username=Linfeng-Tang&show_icons=true&theme=radical&hide_border=true&bg_color=00000000" alt="Linfeng's github stats" />
      </div>
    </td>
  </tr>
</table>

---

### ğŸ”¥ Latest News

- **[2025-12-26]** ğŸ† æˆ‘ä»¬çš„ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://www.cjig.cn/thesisDetails#10.11834/jig.220422&lang=zh)ã€‹è£è· **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2020-2024 ä¼˜ç§€è®ºæ–‡**ï¼
- **[2025-9-18]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ **"ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts"** è¢« **NeurIPS 2025** æ­£å¼æ¥æ”¶! [[è®ºæ–‡ä¸‹è½½](https://arxiv.org/pdf/2503.23356?)] [[Code](https://github.com/Linfeng-Tang/ControlFusion)]
- **[2025-9-10]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ **"Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion"** è¢« **IEEE TPAMI** æ­£å¼æ¥æ”¶! [[è®ºæ–‡ä¸‹è½½](https://ieeexplore.ieee.org/document/11162636)] [[Code](https://github.com/Linfeng-Tang/Mask-DiFuser)]
- **[2025-3-15]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ã€Š[C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning](https://github.com/Linfeng-Tang/C2RF)ã€‹è¢« **IJCV** æ­£å¼æ¥æ”¶ï¼[[è®ºæ–‡ä¸‹è½½](https://link.springer.com/article/10.1007/s11263-025-02427-1)] [[Code](https://github.com/Linfeng-Tang/C2RF)]
- **[2025-02-11]** ğŸ“‚ æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªç”¨äºçº¢å¤–å’Œå¯è§å…‰è§†é¢‘èåˆçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼š[M3SVDï¼šMulti-Modal Multi-Scene Video Dataset](https://github.com/Linfeng-Tang/M3SVD).

<details>
<summary><b>ç‚¹å‡»æŸ¥çœ‹æ›´å¤šå¾€æœŸæ–°é—» (2024åŠä»¥å‰)</b></summary>

- **[2024-12-26]** ğŸ† ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‹è£è· **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2024 ä¼˜ç§€è®ºæ–‡**ï¼[[News](https://mp.weixin.qq.com/s?__biz=MzU1NzM4MjgzOA==&mid=2247536019&idx=1&sn=086193c8064ae58bc1f05de26faaee61)] [[Code](https://github.com/Linfeng-Tang/Image-Fusion)]
- **[2024-11-28]** ğŸ† æˆ‘ä»¬çš„è®ºæ–‡(SeAFusion)ã€Š[Image fusion in the loop of high-level vision tasks](https://www.sciencedirect.com/science/article/pii/S1566253521002542)ã€‹è£è· **Information Fusion Best Paper Award 2024** (æœ€ä½³è®ºæ–‡å¥–)ï¼[[Code](https://github.com/Linfeng-Tang/SeAFusion)]
- **[2024-09]** ğŸŒŸ ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‹å…¥é€‰ **ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡** (å…¨å›½å…±14ç¯‡)ï¼
- **[2024-07-16]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ã€Š[DRMF: Degradation-Robust Multi-Modal Image Fusion](https://openreview.net/forum?id=BwXrlBweab)ã€‹è¢« **ACM MM 2024** æ­£å¼æ¥æ”¶ï¼[[Code](https://github.com/Linfeng-Tang/DRMF)]
- **[2023-11]** ğŸ† æˆ‘ä»¬çš„è®ºæ–‡ã€Š[SwinFusion](https://ieeexplore.ieee.org/document/9812535)ã€‹è£è· **Hsue-shen Tsien Paper Award 2023 (é’±å­¦æ£®è®ºæ–‡å¥–)**ï¼[[Code](https://github.com/Linfeng-Tang/SwinFusion)]

</details>

---

### ğŸ“ Selected Publications

> For a full list, please visit my [Personal Homepage](https://linfeng-tang.github.io/).

#### 2025 & Preprints
* **VideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration** <br>
    ***Linfeng Tang**, Yeda Wang, Meiqi Gong, Zizhuo Li, Yuxin Deng, Xunpeng Yi, Chunyu Li, Han Xu, Hao Zhang, Jiayi Ma* <br>
    **arXiv 2025**. <br>
    [![Paper](https://img.shields.io/badge/Paper-arXiv-b31b1b)](https://arxiv.org/abs/2503.23359)

* **DSPFusion: Image Fusion via Degradation and Semantic Dual-Prior Guidance** <br>
    ***Linfeng Tang**, Chunyu Li, Guoqing Wang, Yixuan Yuan, Jiayi Ma* <br>
    **arXiv 2025**. <br>
    [![Paper](https://img.shields.io/badge/Paper-arXiv-b31b1b)](https://arxiv.org/abs/2503.23355)

* **Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion** <br>
    ***Linfeng Tang**, Chunyu Li, Jiayi Ma* <br>
    **IEEE TPAMI 2025**. <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE_Xplore-blue)](https://doi.org/10.1109/TPAMI.2025.3609323) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/Mask-DiFuser)

* **ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts** <br>
    ***Linfeng Tang**, Yeda Wang, Zhanchuan Cai, Junjun Jiang, Jiayi Ma* <br>
    **NeurIPS 2025** (Oral). <br>
    [![Paper](https://img.shields.io/badge/Paper-OpenReview-b31b1b)](https://openreview.net/forum?id=aLhA7AYLLR) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/ControlFusion)

* **C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning** <br>
    ***Linfeng Tang**, Qinglong Yan, Xinyu Xiang, Leyuan Fang, Jiayi Ma* <br>
    **IJCV 2025**. <br>
    [![Paper](https://img.shields.io/badge/Paper-Springer-blue)](https://link.springer.com/article/10.1007/s11263-025-02427-1) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/C2RF)

#### Highlights (Awarded ğŸ† / ESI Highly Cited Paper ğŸ”¥)

* ğŸ† **Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network** <br>
    ***Linfeng Tang**, Jiteng Yuan, Jiayi Ma* <br>
    **Information Fusion 2022**. (**Best Paper Award 2024**, ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S1566253521002542) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SeAFusion)

* ğŸ† **SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer** <br>
    *Jiayi Ma, **Linfeng Tang**, et al.* <br>
    **IEEE/CAA JAS 2022**. (**Hsue-shen Tsien Paper Award 2023**, ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9812535) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SwinFusion)

* ğŸ† **åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°** <br>
    ***å”éœ–å³°**, å¼ æµ©, å¾æ¶µ, é©¬ä½³ä¹‰* <br>
    **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2023**. (**ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ä¼˜ç§€è®ºæ–‡**) <br>
    [![Paper](https://img.shields.io/badge/Paper-CJIG-red)](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/Image-Fusion)

* ğŸ”¥ **SuperFusion: A Versatile Image Registration and Fusion Network with Semantic Awareness** <br>
    ***Linfeng Tang**, Yuxin Deng, Yong Ma, Jun Huang, Jiayi Ma* <br>
    **IEEE/CAA JAS 2022**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9970457) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SuperFusion)

* ğŸ”¥ **Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity** <br>
    ***Linfeng Tang**, Hao Zhang, Han Xu, Jiayi Ma* <br>
    **Information Fusion 2023**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S1566253523001860) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/PSFusion)

* ğŸ”¥ **DIVFusion: Darkness-free infrared and visible image fusion** <br>
    ***Linfeng Tang**, Xinyu Xiang, Hao Zhang, Meiqi Gong, Jiayi Ma* <br>
    **Information Fusion 2023**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S156625352200210X?via%3Dihub) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/DIVFusion)

* ğŸ”¥ **PIAFusion: A progressive infrared and visible image fusion network based on illumination aware** <br>
    ***Linfeng Tang**, Jiteng Yuan, Hao Zhang, Xingyu Jiang, Jiayi Ma* <br>
    **Information Fusion 2022**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/PIAFusion)

* ğŸ”¥ **STDFusionNet: An Infrared and Visible Image Fusion Network Based on Salient Target Detection** <br>
    *Jiayi Ma, **Linfeng Tang**, Meilong Xu, Hao Zhang, Guobao Xiao* <br>
    **IEEE TIM 2021**. (ESI Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9416507) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/STDFusionNet)


<details>
<summary><b>View More Publications</b></summary>

* **DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior** (**ACM MM 2024**) [[Code](https://github.com/Linfeng-Tang/DRMF)]
* **CAMF: An Interpretable Infrared and Visible Image Fusion Network Based on Class Activation Mapping** (**IEEE TMM 2024**) [[Code](https://github.com/Linfeng-Tang/CAMF)]
* **DRLIE: Flexible Low-light Image Enhancement via Disentangled Representations** (**IEEE TNNLS 2024**) [[Code](https://github.com/Linfeng-Tang/DRLIE)]

</details>

<br>

<details>
<summary><b>ğŸ“š BibTeX (Click to copy)</b></summary>

```bibtex
@article{Tang2025VideoFusion,
  title={VideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration},
  author={Tang, Linfeng and Wang, Yeda and Gong, Meiqi and Li, Zizhuo and Deng, Yuxin and Yi, Xunpeng and Li, Chunyu and Xu, Han and Zhang, Hao and Ma, Jiayi},
  journal={arXiv preprint arXiv:2503.23359},
  year={2025}
}

@article{Tang2025DSPFusion,
  title={DSPFusion: Image Fusion via Degradation and Semantic Dual-Prior Guidance},
  author={Tang, Linfeng and Li, Chunyu and Wang, Guoqing and Yuan, Yixuan and Ma, Jiayi},
  journal={arXiv preprint arXiv:2503.23355},
  year={2025}
}

@article{Tang2025Mask-DiFuser,
  author={Tang, Linfeng and Li, Chunyu and Ma, Jiayi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion}, 
  year={2025},
  volume={48},
  number={1},
  pages={591--608},
}

@inproceedings{Tang2025ControlFusion,
  title={ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts},
  author={Tang, Linfeng and Wang, Yeda and Cai, Zhanchuan and Jiang, Junjun and Ma, Jiayi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2025}
}

@article{Tang2024C2RF,
  title={C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning}, 
  author={Tang, Linfeng and Yan, Qinglong and Xiang, Xinyu and Fang, Leyuan and Ma, Jiayi},
  journal={International Journal of Computer Vision}, 
  pages={5262--5280},
  volume={133},
  year={2025},
}

@inproceedings{Tang2024DRMF,
  title={DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior},
  author={Tang, Linfeng and Deng, Yuxin and Yi, Xunpeng and Yan, Qinglong and Yuan, Yixuan and Ma, Jiayi},
  booktitle={Proceedings of the ACM International Conference on Multimedia},
  pages={8546--8555},
  year={2024}
}

@article{Tang2024CAMF,
  title={CAMF: An Interpretable Infrared and Visible Image Fusion Network Based on Class Activation Mapping}, 
  author={Tang, Linfeng and Chen, Ziang and Huang, Jun and Ma, Jiayi},
  journal={IEEE Transactions on Multimedia}, 
  year={2024},
  volume={26},
  pages={4776-4791},
  publisher={IEEE}
}

@article{Ma2022SwinFusion,
  title={SwinFusion: Cross-domain long-range learning for general image fusion via swin transformer},
  author={Ma, Jiayi and Tang, Linfeng and Fan, Fan and Huang, Jun and Mei, Xiaoguang and Ma, Yong},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={9},
  number={7},
  pages={1200--1217},
  year={2022},
  publisher={IEEE}
}

@article{Tang2022SeAFusion,
  title={Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network},
  author={Tang, Linfeng and Yuan, Jiteng and Ma, Jiayi},
  journal={Information Fusion},
  volume={82},
  pages={28--42},
  year={2022},
  publisher={Elsevier}
}

@article{Tang2022SuperFusion,
  title={SuperFusion: A versatile image registration and fusion network with semantic awareness},
  author={Tang, Linfeng and Deng, Yuxin and Ma, Yong and Huang, Jun and Ma, Jiayi},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={9},
  number={12},
  pages={2121--2137},
  year={2022},
  publisher={IEEE}
}

@article{Tang2023DIVFusion,
  title={DIVFusion: Darkness-free infrared and visible image fusion},
  author={Tang, Linfeng and Xiang, Xinyu and Zhang, Hao and Gong, Meiqi and Ma, Jiayi},
  journal={Infusion Fusion},
  volume={91},
  pages={477--493},
  year={2023},
  publisher={Elsevier}
}

@article{Tang2023PSFusion,
  title={Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity},
  author={Tang, Linfeng and Zhang, Hao and Xu, Han and Ma, Jiayi},
  journal={Information Fusion},
  volume={99},
  pages={101870},
  year={2023},
  publisher={Elsevier}
}

@article{Tang2022PIAFusion,
  title={PIAFusion: A progressive infrared and visible image fusion network based on illumination aware},
  author={Tang, Linfeng and Yuan, Jiteng and Zhang, Hao and Jiang, Xingyu and Ma, Jiayi},
  journal={Infusion Fusion},
  volume={83},
  pages={79--92},
  year={2022},
  publisher={Elsevier}
}

@article{Ma2021STDFusionNet,
  title = {STDFusionNet: An infrared and visible image fusion network based on salient target detection},
  author = {Ma, Jiayi and Tang, Linfeng and Xu, Meilong and Zhang, Hao and Xiao, Guobao},
  journal = {IEEE Transactions on Instrumentation and Measurement},
  volume = {70},
  pages = {5009513},
  year = {2021},
  publisher = {IEEE}
}
