<div align="center">
  <h1>Hi there, I'm Linfeng Tang (å”éœ–å³°) ğŸ‘‹</h1>
  
  <h3>PhD Student @ <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a></h3>
  
  <p>
    <b>Research Interests:</b> Multi-modal Image Fusion, Image Enhancement, Visual-Semantic Understanding
  </p>

  <a href="https://linfeng-tang.github.io/">
    <img src="https://img.shields.io/badge/ğŸ _Personal_Homepage-Visit_Now-2ea44f?style=for-the-badge&logo=github" alt="Website">
  </a>

  <p>
    <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
      <img src="https://img.shields.io/badge/Google_Scholar-PyRqpAsAAAAJ-4285F4?style=flat&logo=google-scholar&logoColor=white" alt="Google Scholar">
    </a>
    <a href="mailto:linfeng0419@gmail.com">
      <img src="https://img.shields.io/badge/Email-linfeng0419@gmail.com-D14836?style=flat&logo=gmail&logoColor=white" alt="Email">
    </a>
    <a href="https://www.researchgate.net/profile/Tang-Linfeng-2">
      <img src="https://img.shields.io/badge/ResearchGate-Linfeng_Tang-00CCBB?style=flat&logo=ResearchGate&logoColor=white" alt="ResearchGate">
    </a>
    <a href="https://linfeng-tang.github.io/wechat.html" target="_blank">
      <img src="https://img.shields.io/badge/WeChat-Click_To_Add-07C160?style=flat&logo=wechat&logoColor=white" alt="WeChat">
    </a>
  </p>
</div>

---

<table>
  <tr>
    <td width="60%" valign="top">
      <h3>ğŸ”­ About Me</h3>
      <p>
        I am a PhD student at the <b>School of Electronic Information, Wuhan University</b>. My research primarily focuses on Computer Vision and Deep Learning.
      </p>
      <p>
        <b>Main Research Topics:</b>
      </p>
      <ul>
        <li><b>Information Fusion</b> (Multi-modal Image Fusion, Video Fusion)</li>
        <li><b>Image Enhancement</b> (Low-light Enhancement)</li>
        <li><b>Visual-Semantic Understanding</b></li>
      </ul>
    </td>
    <td width="40%" valign="center">
      <div align="center">
        <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
          <img src="https://img.shields.io/badge/Google_Scholar-Stats-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white" alt="Google Scholar">
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
          <img src="https://img.shields.io/badge/Citations-5493-blue?style=flat-square&logo=google-scholar&logoColor=white" />
        </a>
        <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
          <img src="https://img.shields.io/badge/h--index-17-blue?style=flat-square" />
        </a>
        <a href="https://scholar.google.com/citations?user=PyRqpAsAAAAJ&hl=zh-CN">
          <img src="https://img.shields.io/badge/i10--index-19-blue?style=flat-square" />
        </a>
        <br><br>
        <img src="https://streak-stats.demolab.com?user=Linfeng-Tang&theme=radical&hide_border=true&date_format=M%20j%5B%2C%20Y%5D" alt="Linfeng's Streak" />
      </div>
    </td>
  </tr>
</table>

---

### ğŸ”¥ Latest News

- **[2025-12-26]** ğŸ† æˆ‘ä»¬çš„ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://www.cjig.cn/thesisDetails#10.11834/jig.220422&lang=zh)ã€‹è£è· **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2020-2024 ä¼˜ç§€è®ºæ–‡**ï¼
- **[2025-9-18]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ **"ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts"** è¢« **NeurIPS 2025** æ­£å¼æ¥æ”¶! [[è®ºæ–‡ä¸‹è½½](https://arxiv.org/pdf/2503.23356?)] [[Code](https://github.com/Linfeng-Tang/ControlFusion)]
- **[2025-9-10]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ **"Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion"** è¢« **IEEE TPAMI** æ­£å¼æ¥æ”¶! [[è®ºæ–‡ä¸‹è½½](https://ieeexplore.ieee.org/document/11162636)] [[Code](https://github.com/Linfeng-Tang/Mask-DiFuser)]
- **[2025-3-15]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ã€Š[C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning](https://github.com/Linfeng-Tang/C2RF)ã€‹è¢« **IJCV** æ­£å¼æ¥æ”¶ï¼[[è®ºæ–‡ä¸‹è½½](https://link.springer.com/article/10.1007/s11263-025-02427-1)] [[Code](https://github.com/Linfeng-Tang/C2RF)]
- **[2025-02-11]** ğŸ“‚ æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªç”¨äºçº¢å¤–å’Œå¯è§å…‰è§†é¢‘èåˆçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼š[M3SVDï¼šMulti-Modal Multi-Scene Video Dataset](https://github.com/Linfeng-Tang/M3SVD).
- **[2024-12-26]** ğŸ† ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‹è£è· **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ 2024 ä¼˜ç§€è®ºæ–‡**ï¼[[News](https://mp.weixin.qq.com/s?__biz=MzU1NzM4MjgzOA==&mid=2247536019&idx=1&sn=086193c8064ae58bc1f05de26faaee61)] [[Code](https://github.com/Linfeng-Tang/Image-Fusion)]
- **[2024-11-28]** ğŸ† æˆ‘ä»¬çš„è®ºæ–‡(SeAFusion)ã€Š[Image fusion in the loop of high-level vision tasks](https://www.sciencedirect.com/science/article/pii/S1566253521002542)ã€‹è£è· **Information Fusion Best Paper Award 2024** (æœ€ä½³è®ºæ–‡å¥–)ï¼[[Code](https://github.com/Linfeng-Tang/SeAFusion)]
- **[2024-09]** ğŸŒŸ ç»¼è¿°ã€Š[åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‹å…¥é€‰ **ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡** (å…¨å›½å…±14ç¯‡)ï¼
- **[2024-07-16]** ğŸ‰ æˆ‘ä»¬çš„è®ºæ–‡ã€Š[DRMF: Degradation-Robust Multi-Modal Image Fusion](https://openreview.net/forum?id=BwXrlBweab)ã€‹è¢« **ACM MM 2024** æ­£å¼æ¥æ”¶ï¼[[Code](https://github.com/Linfeng-Tang/DRMF)]
- **[2023-11]** ğŸ† æˆ‘ä»¬çš„è®ºæ–‡ã€Š[SwinFusion](https://ieeexplore.ieee.org/document/9812535)ã€‹è£è· **Hsue-shen Tsien Paper Award 2023 (é’±å­¦æ£®è®ºæ–‡å¥–)**ï¼[[Code](https://github.com/Linfeng-Tang/SwinFusion)]

---

### ğŸ“ Selected Publications

> For a full list, please visit my [Personal Homepage](https://linfeng-tang.github.io/).

#### 2026 & 2025
* âœ¨ **Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion** <br>
    ***Linfeng Tang**, Chunyu Li, Jiayi Ma* <br>
    **IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI)**, vol. 48, no. 1, pp. 591-608, Jan. 2026. <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE_Xplore-blue)](https://doi.org/10.1109/TPAMI.2025.3609323) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/Mask-DiFuser)

* âœ¨ **ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts** <br>
    ***Linfeng Tang**, Yeda Wang, Zhanchuan Cai, Junjun Jiang, Jiayi Ma* <br>
    **Advances in Neural Information Processing Systems (NeurIPS)**, Dec. 2025 (Oral). <br>
    [![Paper](https://img.shields.io/badge/Paper-OpenReview-b31b1b)](https://openreview.net/forum?id=aLhA7AYLLR) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/ControlFusion)

* âœ¨ **C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning** <br>
    ***Linfeng Tang**, Qinglong Yan, Xinyu Xiang, Leyuan Fang, Jiayi Ma* <br>
    **International Journal of Computer Vision (IJCV)**, vol. 133, pp. 5262-5280, 2025. <br>
    [![Paper](https://img.shields.io/badge/Paper-Springer-blue)](https://link.springer.com/article/10.1007/s11263-025-02427-1) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/C2RF)

#### Highlights (Awarded ğŸ† / ESI Highly Cited ğŸ”¥)

* ğŸ† **SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer** <br>
    *Jiayi Ma, **Linfeng Tang**, et al.* <br>
    **IEEE/CAA Journal of Automatica Sinica (IEEE/CAA JAS)**, 2022. <br>
    (**Hsue-shen Tsien Paper Award 2023**, ESI Hot & Highly Cited Paper) <br>
     [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9812535) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SwinFusion) [![Citations](https://img.shields.io/badge/Cited_by-1145-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:u-x6o8ySG0sC)

* ğŸ† **Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network** <br>
    ***Linfeng Tang**, Jiteng Yuan, Jiayi Ma* <br>
    **Information Fusion 2022**. <br>
    (**Best Paper Award 2024**, ESI Hot & Highly Cited Paper) <br>
     [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S1566253521002542) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SeAFusion) [![Citations](https://img.shields.io/badge/Cited_by-907-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:u5HHmVD_uO8C)

* ğŸ”¥ **PIAFusion: A progressive infrared and visible image fusion network based on illumination aware** <br>
    ***Linfeng Tang**, Jiteng Yuan, Hao Zhang, Xingyu Jiang, Jiayi Ma* <br>
    **Information Fusion 2022**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/PIAFusion) [![Citations](https://img.shields.io/badge/Cited_by-901-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:YsMSGLbcyi4C) 

* ğŸ”¥ **STDFusionNet: An Infrared and Visible Image Fusion Network Based on Salient Target Detection** <br>
    *Jiayi Ma, **Linfeng Tang**, Meilong Xu, Hao Zhang, Guobao Xiao* <br>
    **IEEE Transactions on Instrumentation and Measurement (IEEE TIM)**, 2021. (ESI Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9416507) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/STDFusionNet) [![Citations](https://img.shields.io/badge/Cited_by-565-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:9yKSN-GCB0IC) 

* ğŸ”¥ **DIVFusion: Darkness-free infrared and visible image fusion** <br>
    ***Linfeng Tang**, Xinyu Xiang, Hao Zhang, Meiqi Gong, Jiayi Ma* <br>
    **Information Fusion 2023**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S156625352200210X?via%3Dihub) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/DIVFusion) [![Citations](https://img.shields.io/badge/Cited_by-402-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:W7OEmFMy1ooC) 

* ğŸ”¥ **SuperFusion: A Versatile Image Registration and Fusion Network with Semantic Awareness** <br>
    ***Linfeng Tang**, Yuxin Deng, Yong Ma, Jun Huang, Jiayi Ma* <br>
    **IEEE/CAA Journal of Automatica Sinica (IEEE/CAA JAS)**, 2022. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-IEEE-blue)](https://ieeexplore.ieee.org/document/9970457) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/SuperFusion) [![Citations](https://img.shields.io/badge/Cited_by-381-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:eQOLeE2rZwMC) 

* ğŸ”¥ **Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity** <br>
    ***Linfeng Tang**, Hao Zhang, Han Xu, Jiayi Ma* <br>
    **Information Fusion 2023**. (ESI Hot & Highly Cited Paper) <br>
    [![Paper](https://img.shields.io/badge/Paper-ScienceDirect-orange)](https://www.sciencedirect.com/science/article/pii/S1566253523001860) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/PSFusion) [![Citations](https://img.shields.io/badge/Cited_by-278-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:Tyk-4Ss8FVUC) 

* ğŸ† **åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°** <br>
    ***å”éœ–å³°**, å¼ æµ©, å¾æ¶µ, é©¬ä½³ä¹‰* <br>
    **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ (JIG)**, 2023. <br>
    (**ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥2020-2024ä¼˜ç§€è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥2024å¹´åº¦ä¼˜ç§€è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥å­¦æœ¯è®ºå›ä¼˜ç§€æŠ¥å‘Šæˆæœ**) <br>
    [![Paper](https://img.shields.io/badge/Paper-JIG-red)](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/Image-Fusion) [![Citations](https://img.shields.io/badge/Cited_by-88-blueviolet)](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=PyRqpAsAAAAJ&citation_for_view=PyRqpAsAAAAJ:qjMakFHDy7sC) 
  
* âœ¨ **DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior** <br>
    ***Linfeng Tang**, Yuxin Deng, Xunpeng Yi, Qinglong Yan, Yixuan Yuan, Jiayi Ma* <br>
    **Proceedings of the ACM International Conference on Multimedia (ACM MM)**, 2024. (**CCF-A**) <br>
    [![Paper](https://img.shields.io/badge/Paper-ACM_DL-blue)](https://dl.acm.org/doi/10.1145/3664647.3681064) [![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Linfeng-Tang/DRMF)

<br>

<details>
<summary><b>âš¡ Full List of Publications (1-15)</b></summary>

1. **Linfeng Tang**, Chunyu Li, and Jiayi Ma. "Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion", **IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI)**, vol. 48, no. 1, pp. 591-608, Jan. 2026.ã€[Paper](https://doi.org/10.1109/TPAMI.2025.3609323)ã€‘ã€[Code](https://github.com/Linfeng-Tang/Mask-DiFuser)ã€‘
2. **Linfeng Tang**, Yeda Wang, Zhanchuan Cai, Junjun Jiang, and Jiayi Ma. "ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts", in **Advances in Neural Information Processing Systems (NeurIPS)**, Dec. 2025 (Oral, Acceptance rate: 0.36%).ã€[Paper](https://openreview.net/forum?id=aLhA7AYLLR)ã€‘ã€[Code](https://github.com/Linfeng-Tang/ControlFusion)ã€‘
3. **Linfeng Tang**, Qinglong Yan, Xinyu Xiang, Leyuan Fang, and Jiayi Ma. "C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning", **International Journal of Computer Vision (IJCV)**, vol. 133, pp. 5262-5280, 2025. ã€[Paper](https://github.com/Linfeng-Tang/C2RF)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/C2RF)ã€‘ 
4. **Linfeng Tang**, Jiteng Yuan, and Jiayi Ma. "Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network", **Information Fusion**, 82, pp. 28-42, 2022. (**Information Fusion Best Paper Award 2024 (æœ€ä½³è®ºæ–‡å¥–)**, ESI Hot & Highly Cited Paper)ã€[Paper](https://www.sciencedirect.com/science/article/pii/S1566253521002542)ã€‘ã€[Code](https://github.com/Linfeng-Tang/SeAFusion)ã€‘
5. Jiayi Ma, **Linfeng Tang**, Fan Fan, Jun Huang, Xiaoguang Mei, and Yong Ma. "SwinFusion: Cross-domain Long-range Learning for General Image Fusion via Swin Transformer", **IEEE/CAA Journal of Automatica Sinica (IEEE/CAA JAS)**, 9(7), pp. 1200-1217, 2022. (Hsue-shen Tsien Paper Award 2023 (é’±å­¦æ£®è®ºæ–‡å¥–ï¼ŒIEEE/CAA JASæœ€ä½³è®ºæ–‡å¥–), ESI Hot & Highly Cited Paper)ã€[Paper](https://ieeexplore.ieee.org/document/9812535)ã€‘ã€[Code](https://github.com/Linfeng-Tang/SwinFusion)ã€‘
6. **Linfeng Tang**, Yuxin Deng, Yong Ma, Jun Huang, and Jiayi Ma. "SuperFusion: A Versatile Image Registration and Fusion Network with Semantic Awareness", **IEEE/CAA Journal of Automatica Sinica (IEEE/CAA JAS)**, 9(12), pp. 2121-2137, 2022. (ESI Hot & Highly Cited Paper).ã€[Paper](https://ieeexplore.ieee.org/document/9970457)ã€‘ã€[Code](https://github.com/Linfeng-Tang/SuperFusion)ã€‘
7. **Linfeng Tang**, Hao Zhang, Han Xu, and Jiayi Ma. "Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity", **Information Fusion**, 99, pp. 101870, 2023. (ESI Hot & Highly Cited Paper)ã€[Paper](https://www.sciencedirect.com/science/article/pii/S1566253523001860)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/PSFusion)ã€‘ 
8. **Linfeng Tang**, Yuxin Deng, Xunpeng Yi, Qinglong Yan, Yixuan Yuan, and Jiayi Ma. "DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior", in **Proceedings of the ACM International Conference on Multimedia (ACM MM)**, Nov. 2024.ã€[Paper](https://dl.acm.org/doi/10.1145/3664647.3681064)ã€‘ã€[Code](https://github.com/Linfeng-Tang/DRMF)ã€‘
9. **Linfeng Tang**, Xinyu Xiang, Hao Zhang, Meiqi Gong, and Jiayi Ma. "DIVFusion: Darkness-free infrared and visible image fusion", **Information Fusion**, 91, pp. 477-493, 2023. (ESI Hot & Highly Cited Paper)ã€[Paper](https://www.sciencedirect.com/science/article/pii/S156625352200210X?via%3Dihub)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/DIVFusion)ã€‘
10. **Linfeng Tang**, Jiteng Yuan, Hao Zhang, Xingyu Jiang, and Jiayi Ma. "PIAFusion: A progressive infrared and visible image fusion network based on illumination aware", **Information Fusion**, 83-84, pp. 79-92, 2022. (ESI Hot & Highly Cited Paper)ã€[Paper](https://www.sciencedirect.com/science/article/abs/pii/S156625352200032X)ã€‘ã€[Code](https://github.com/Linfeng-Tang/PIAFusion)ã€‘
11. **Linfeng Tang**, Jiayi Ma, Hao Zhang, and Xiaojie Guo. "DRLIE: Flexible Low-light Image Enhancement via Disentangled Representations", **IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS)**, 35(2), pp. 2694-2707, 2024.ã€[Paper](https://ieeexplore.ieee.org/document/9833451)ã€‘ã€[Code](https://github.com/Linfeng-Tang/DRLIE)ã€‘
12. Jiayi Ma, **Linfeng Tang**, Meilong Xu, Hao Zhang, and Guobao Xiao. "STDFusionNet: An Infrared and Visible Image Fusion Network Based on Salient Target Detection", **IEEE Transactions on Instrumentation and Measurement (IEEE TIM)**, 70, pp. 5009513, 2021.(ESI Highly Cited Paper)ã€[Paper](https://ieeexplore.ieee.org/document/9416507)ã€‘ ã€[Code](https://github.com/Linfeng-Tang/STDFusionNet)ã€‘
13. Meilong Xu, **Linfeng Tang**, Hao Zhang, and Jiayi Ma. "Infrared and visible image fusion via parallel scene and texture learning", **Pattern Recognition (PR)**, 132, pp. 108929, 2022.ã€[Paper](https://www.sciencedirect.com/science/article/pii/S0031320322004101)ã€‘ã€[Code](https://github.com/Melon-Xu/PSTLFusion)ã€‘
14. **Linfeng Tang**, Ziang Chen, Jun Huang, and Jiayi Ma. "CAMF: An Interpretable Infrared and Visible Image Fusion Network Based on Class Activation Mapping", **IEEE Transactions on Multimedia (IEEE TMM)**, 26, pp. 4776-4791, 2024.ã€[Paper](https://ieeexplore.ieee.org/document/10288391)ã€‘ã€[Code](https://github.com/Linfeng-Tang/CAMF)ã€‘
15. **å”éœ–å³°**, å¼ æµ©, å¾æ¶µ, é©¬ä½³ä¹‰. åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒèåˆæ–¹æ³•ç»¼è¿°. **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ (JIG)**, 28(1), pp. 3-36, 2023. (**ç©ºå¤©ä¿¡æ¯ç§‘æŠ€æœŸåˆŠé«˜å½±å“åŠ›è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥2020-2024ä¼˜ç§€è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥2024å¹´åº¦ä¼˜ç§€è®ºæ–‡**, **ä¸­å›½å›¾è±¡å›¾å½¢å­¦æŠ¥ä¼˜ç§€æˆæœæŠ¥å‘Š**)ã€[Paper](https://txtx.publish.founderss.cn/zh/article/doi/10.11834/jig.220422/)ã€‘ã€[Code](https://github.com/Linfeng-Tang/Image-Fusion)ã€‘

</details>

<br>

<details>
<summary><b>ğŸ“š BibTeX (Click to copy)</b></summary>

```bibtex
@article{Tang2025VideoFusion,
  title={VideoFusion: A Spatio-Temporal Collaborative Network for Multi-modal Video Fusion and Restoration},
  author={Tang, Linfeng and Wang, Yeda and Gong, Meiqi and Li, Zizhuo and Deng, Yuxin and Yi, Xunpeng and Li, Chunyu and Xu, Han and Zhang, Hao and Ma, Jiayi},
  journal={arXiv preprint arXiv:2503.23359},
  year={2025}
}

@article{Tang2025DSPFusion,
  title={DSPFusion: Image Fusion via Degradation and Semantic Dual-Prior Guidance},
  author={Tang, Linfeng and Li, Chunyu and Wang, Guoqing and Yuan, Yixuan and Ma, Jiayi},
  journal={arXiv preprint arXiv:2503.23355},
  year={2025}
}

@article{Tang2026Mask-DiFuser,
  author={Tang, Linfeng and Li, Chunyu and Ma, Jiayi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Mask-DiFuser: A Masked Diffusion Model for Unified Unsupervised Image Fusion}, 
  year={2026},
  volume={48},
  number={1},
  pages={591--608},
}

@inproceedings{Tang2025ControlFusion,
  title={ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts},
  author={Tang, Linfeng and Wang, Yeda and Cai, Zhanchuan and Jiang, Junjun and Ma, Jiayi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2025}
}

@article{Tang2024C2RF,
  title={C2RF: Bridging Multi-modal Image Registration and Fusion via Commonality Mining and Contrastive Learning}, 
  author={Tang, Linfeng and Yan, Qinglong and Xiang, Xinyu and Fang, Leyuan and Ma, Jiayi},
  journal={International Journal of Computer Vision}, 
  pages={5262--5280},
  volume={133},
  year={2025},
}

@inproceedings{Tang2024DRMF,
  title={DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior},
  author={Tang, Linfeng and Deng, Yuxin and Yi, Xunpeng and Yan, Qinglong and Yuan, Yixuan and Ma, Jiayi},
  booktitle={Proceedings of the ACM International Conference on Multimedia},
  pages={8546--8555},
  year={2024}
}

@article{Tang2024CAMF,
  title={CAMF: An Interpretable Infrared and Visible Image Fusion Network Based on Class Activation Mapping}, 
  author={Tang, Linfeng and Chen, Ziang and Huang, Jun and Ma, Jiayi},
  journal={IEEE Transactions on Multimedia}, 
  year={2024},
  volume={26},
  pages={4776-4791},
  publisher={IEEE}
}

@article{Ma2022SwinFusion,
  title={SwinFusion: Cross-domain long-range learning for general image fusion via swin transformer},
  author={Ma, Jiayi and Tang, Linfeng and Fan, Fan and Huang, Jun and Mei, Xiaoguang and Ma, Yong},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={9},
  number={7},
  pages={1200--1217},
  year={2022},
  publisher={IEEE}
}

@article{Tang2022SeAFusion,
  title={Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network},
  author={Tang, Linfeng and Yuan, Jiteng and Ma, Jiayi},
  journal={Information Fusion},
  volume={82},
  pages={28--42},
  year={2022},
  publisher={Elsevier}
}

@article{Tang2022SuperFusion,
  title={SuperFusion: A versatile image registration and fusion network with semantic awareness},
  author={Tang, Linfeng and Deng, Yuxin and Ma, Yong and Huang, Jun and Ma, Jiayi},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={9},
  number={12},
  pages={2121--2137},
  year={2022},
  publisher={IEEE}
}

@article{Tang2023DIVFusion,
  title={DIVFusion: Darkness-free infrared and visible image fusion},
  author={Tang, Linfeng and Xiang, Xinyu and Zhang, Hao and Gong, Meiqi and Ma, Jiayi},
  journal={Infusion Fusion},
  volume={91},
  pages={477--493},
  year={2023},
  publisher={Elsevier}
}

@article{Tang2023PSFusion,
  title={Rethinking the necessity of image fusion in high-level vision tasks: A practical infrared and visible image fusion network based on progressive semantic injection and scene fidelity},
  author={Tang, Linfeng and Zhang, Hao and Xu, Han and Ma, Jiayi},
  journal={Information Fusion},
  volume={99},
  pages={101870},
  year={2023},
  publisher={Elsevier}
}

@article{Tang2022PIAFusion,
  title={PIAFusion: A progressive infrared and visible image fusion network based on illumination aware},
  author={Tang, Linfeng and Yuan, Jiteng and Zhang, Hao and Jiang, Xingyu and Ma, Jiayi},
  journal={Infusion Fusion},
  volume={83},
  pages={79--92},
  year={2022},
  publisher={Elsevier}
}

@article{Ma2021STDFusionNet,
  title = {STDFusionNet: An infrared and visible image fusion network based on salient target detection},
  author = {Ma, Jiayi and Tang, Linfeng and Xu, Meilong and Zhang, Hao and Xiao, Guobao},
  journal = {IEEE Transactions on Instrumentation and Measurement},
  volume = {70},
  pages = {5009513},
  year = {2021},
  publisher = {IEEE}
}
